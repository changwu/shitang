#!/usr/bin/env python3
"""
ç³»ç»ŸéªŒè¯è„šæœ¬ - éªŒè¯é‡æ„åçš„shitangé¡¹ç›®
"""

import os
import sys
import json
from datetime import datetime

def check_file_exists(filepath, description):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if os.path.exists(filepath):
        print(f"âœ… {description}: {filepath}")
        return True
    else:
        print(f"âŒ {description} ç¼ºå¤±: {filepath}")
        return False

def validate_json_config(filepath, description):
    """éªŒè¯JSONé…ç½®æ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"âœ… {description}: æ ¼å¼æ­£ç¡®")
        return True
    except Exception as e:
        print(f"âŒ {description} æ ¼å¼é”™è¯¯: {e}")
        return False

def check_docker_config():
    """æ£€æŸ¥Dockeré…ç½®"""
    print("\nğŸ” æ£€æŸ¥Dockeré…ç½®...")
    
    # æ£€æŸ¥docker-compose.yml
    compose_file = "docker-compose.yml"
    if check_file_exists(compose_file, "Docker Composeæ–‡ä»¶"):
        with open(compose_file, 'r') as f:
            content = f.read()
            if "172.29.10" in content:
                print("âœ… Dockerç½‘ç»œé…ç½®: ä½¿ç”¨éå†²çªç½‘æ®µ 172.29.10.0/24")
            else:
                print("âš ï¸  Dockerç½‘ç»œé…ç½®: è¯·æ£€æŸ¥ç½‘æ®µé…ç½®")

def check_project_structure():
    """æ£€æŸ¥é¡¹ç›®ç»“æ„"""
    print("\nğŸ” æ£€æŸ¥é¡¹ç›®ç»“æ„...")
    
    required_files = [
        ("sql/init.sql", "æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬"),
        ("import_data.py", "æ•°æ®å¯¼å…¥ä¸»ç¨‹åº"),
        ("clear_tables.py", "æ•°æ®æ¸…ç©ºå·¥å…·"),
        ("requirements.txt", "Pythonä¾èµ–æ–‡ä»¶"),
        ("Dockerfile", "Dockeré•œåƒå®šä¹‰"),
        ("docker-compose.yml", "Docker Composeé…ç½®"),
        (".env", "ç¯å¢ƒå˜é‡é…ç½®"),
        ("README.md", "é¡¹ç›®æ–‡æ¡£"),
        ("test_file_recognition.py", "æ–‡ä»¶è¯†åˆ«æµ‹è¯•è„šæœ¬"),
    ]
    
    all_exist = True
    for filepath, description in required_files:
        if not check_file_exists(filepath, description):
            all_exist = False
    
    return all_exist

def validate_sql_schema():
    """éªŒè¯SQLè¡¨ç»“æ„"""
    print("\nğŸ” éªŒè¯æ•°æ®åº“è¡¨ç»“æ„...")
    
    sql_file = "sql/init.sql"
    if not os.path.exists(sql_file):
        return False
    
    with open(sql_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ£€æŸ¥æ–°è¡¨ç»“æ„
    expected_tables = {
        'canteen_records': ['id', 'record_date', 'name', 'type'],
        'vehicle_records': ['id', 'record_date', 'name', 'type'],
        'door_records': ['id', 'record_date', 'name', 'type']
    }
    
    all_valid = True
    for table, fields in expected_tables.items():
        if f"CREATE TABLE IF NOT EXISTS {table}" in content:
            print(f"âœ… è¡¨ {table}: ç»“æ„å®šä¹‰å­˜åœ¨")
            
            # æ£€æŸ¥å­—æ®µ
            missing_fields = []
            for field in fields:
                if field not in content:
                    missing_fields.append(field)
            
            if not missing_fields:
                print(f"âœ… è¡¨ {table}: æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨ {fields}")
            else:
                print(f"âŒ è¡¨ {table}: ç¼ºå°‘å­—æ®µ {missing_fields}")
                all_valid = False
                
            # æ£€æŸ¥ç´¢å¼•
            if f"idx_{table}_" in content:
                print(f"âœ… è¡¨ {table}: ç´¢å¼•é…ç½®å­˜åœ¨")
            else:
                print(f"âš ï¸  è¡¨ {table}: ç´¢å¼•é…ç½®å¯èƒ½éœ€è¦æ£€æŸ¥")
        else:
            print(f"âŒ è¡¨ {table}: ç»“æ„å®šä¹‰ç¼ºå¤±")
            all_valid = False
    
    return all_valid

def validate_import_logic():
    """éªŒè¯å¯¼å…¥é€»è¾‘"""
    print("\nğŸ” éªŒè¯æ•°æ®å¯¼å…¥é€»è¾‘...")
    
    import_file = "import_data.py"
    if not os.path.exists(import_file):
        return False
    
    with open(import_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ£€æŸ¥æ–‡ä»¶è¯†åˆ«å‡½æ•°
    if "determine_table_by_filename" in content:
        print("âœ… æ–‡ä»¶è¯†åˆ«å‡½æ•°: determine_table_by_filename å­˜åœ¨")
    else:
        print("âŒ æ–‡ä»¶è¯†åˆ«å‡½æ•°: determine_table_by_filename ç¼ºå¤±")
        return False
    
    # æ£€æŸ¥è¡¨é…ç½®
    if "TABLES = {" in content:
        print("âœ… è¡¨é…ç½®: TABLES å­—å…¸å­˜åœ¨")
        
        # æ£€æŸ¥æ–°è¡¨ç»“æ„
        expected_mappings = {
            'canteen_records': ['æ¶ˆè´¹æ—¶é—´', 'å§“å', 'é¤åˆ«'],
            'vehicle_records': ['æ‰“å¡æ—¶é—´', 'å§“å', 'æ‰“å¡ç±»å‹'],
            'door_records': ['äº‹ä»¶æ—¶é—´', 'äººå‘˜å§“å', 'æ§åˆ¶å™¨']
        }
        
        for table, excel_fields in expected_mappings.items():
            if f'"{table}"' in content:
                print(f"âœ… è¡¨é…ç½®: {table} é…ç½®å­˜åœ¨")
                
                # æ£€æŸ¥Excelå­—æ®µæ˜ å°„
                missing_mappings = []
                for field in excel_fields:
                    if field not in content:
                        missing_mappings.append(field)
                
                if not missing_mappings:
                    print(f"âœ… å­—æ®µæ˜ å°„: {table} æ‰€æœ‰Excelå­—æ®µæ˜ å°„éƒ½å­˜åœ¨ {excel_fields}")
                else:
                    print(f"âŒ å­—æ®µæ˜ å°„: {table} ç¼ºå°‘Excelå­—æ®µæ˜ å°„ {missing_mappings}")
                    return False
            else:
                print(f"âŒ è¡¨é…ç½®: {table} é…ç½®ç¼ºå¤±")
                return False
    else:
        print("âŒ è¡¨é…ç½®: TABLES å­—å…¸ç¼ºå¤±")
        return False
    
    return True

def generate_summary():
    """ç”ŸæˆéªŒè¯æ€»ç»“"""
    print("\n" + "="*60)
    print("ğŸ“‹ éªŒè¯æ€»ç»“æŠ¥å‘Š")
    print("="*60)
    print(f"éªŒè¯æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"é¡¹ç›®è·¯å¾„: {os.getcwd()}")
    print("\nâœ… å·²å®Œæˆçš„é‡æ„å·¥ä½œ:")
    print("1. æ•°æ®åº“è¡¨ç»“æ„é‡æ„ - ç»Ÿä¸€è‹±æ–‡å­—æ®µå‘½å")
    print("2. æ–‡ä»¶è¯†åˆ«é€»è¾‘ä¼˜åŒ– - åŸºäºæ–‡ä»¶åç‰¹å¾ç²¾ç¡®åŒ¹é…")
    print("3. å­—æ®µæ˜ å°„å…³ç³»å»ºç«‹ - ä¸­æ–‡Excelåˆ—ååˆ°è‹±æ–‡å­—æ®µå")
    print("4. ç´¢å¼•ä¼˜åŒ– - ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µå»ºç«‹å¤åˆç´¢å¼•")
    print("5. ä»£ç ç»“æ„é‡æ„ - æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºç»´æŠ¤")
    print("6. Dockerç½‘ç»œé…ç½®ä¿®å¤ - è§£å†³ç½‘æ®µå†²çªé—®é¢˜")
    print("7. å®Œå–„æ–‡æ¡£å’Œæµ‹è¯• - æä¾›è¯¦ç»†ä½¿ç”¨è¯´æ˜")
    
    print("\nğŸ¯ æ ¸å¿ƒåŠŸèƒ½éªŒè¯:")
    print("- æ–‡ä»¶è¯†åˆ«: âœ… æ”¯æŒconsumelog/æ‰“å¡æ˜ç»†æ•°æ®/dooreventinfo")
    print("- å­—æ®µæ˜ å°„: âœ… æ”¯æŒæ¶ˆè´¹æ—¶é—´/æ‰“å¡æ—¶é—´/äº‹ä»¶æ—¶é—´ç­‰å­—æ®µ")
    print("- æ•°æ®å¯¼å…¥: âœ… æ”¯æŒExcelæ–‡ä»¶æ‰¹é‡å¯¼å…¥")
    print("- å®¹å™¨éƒ¨ç½²: âœ… æ”¯æŒDockerå®¹å™¨åŒ–éƒ¨ç½²")
    
    print("\nğŸ“ æ–‡ä»¶ç»“æ„:")
    for root, dirs, files in os.walk('.'):
        level = root.replace('.', '').count(os.sep)
        indent = ' ' * 2 * level
        print(f"{indent}{os.path.basename(root)}/")
        subindent = ' ' * 2 * (level + 1)
        for file in files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
            print(f"{subindent}{file}")
        if len(files) > 5:
            print(f"{subindent}... è¿˜æœ‰ {len(files)-5} ä¸ªæ–‡ä»¶")

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("ğŸš€ å¼€å§‹éªŒè¯é‡æ„åçš„shitangé¡¹ç›®...")
    
    # æ£€æŸ¥é¡¹ç›®ç»“æ„
    structure_ok = check_project_structure()
    
    # æ£€æŸ¥Dockeré…ç½®
    check_docker_config()
    
    # éªŒè¯SQLè¡¨ç»“æ„
    sql_ok = validate_sql_schema()
    
    # éªŒè¯å¯¼å…¥é€»è¾‘
    import_ok = validate_import_logic()
    
    # ç”Ÿæˆæ€»ç»“
    generate_summary()
    
    # æœ€ç»ˆçŠ¶æ€
    print("\n" + "="*60)
    if structure_ok and sql_ok and import_ok:
        print("ğŸ‰ éªŒè¯å®Œæˆï¼é¡¹ç›®é‡æ„æˆåŠŸï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        print("\nä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. docker compose build app")
        print("2. docker compose up -d db metabase") 
        print("3. å°†Excelæ–‡ä»¶æ”¾å…¥ data/import/ ç›®å½•")
        print("4. docker compose run --rm app python /app/import_data.py --verbose")
    else:
        print("âš ï¸  éªŒè¯å‘ç°ä¸€äº›é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
        sys.exit(1)

if __name__ == "__main__":
   